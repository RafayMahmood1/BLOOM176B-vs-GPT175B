{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05441a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafay/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|█████████████████████████████| 222/222 [00:00<00:00, 67.9kB/s]\n",
      "Downloading: 100%|█████████████████████████| 14.5M/14.5M [00:05<00:00, 2.54MB/s]\n",
      "Downloading: 100%|███████████████████████████| 85.0/85.0 [00:00<00:00, 29.7kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63328a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preProcessText(text):\n",
    "    # remove links\n",
    "    text = re.sub(\n",
    "        \"(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\",\n",
    "        \" \",\n",
    "        text,\n",
    "    )\n",
    "\n",
    "    text = re.sub(r\"\\n\", \" \", text)  # remove /r /n etc\n",
    "    text = re.sub(r\"\\r\", \" \", text)  # remove /r /n etc\n",
    "    text = re.sub(r\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = re.split(\"^\\s*(On\\s([a-zA-Z]){3}.*)\", text, flags=re.M)[0] \n",
    "    text = re.split(\"^\\s*(From:\\s([a-zA-Z]){3}.*)\", text, flags=re.M)[0]\n",
    "    text = text.split(\"wrote:\")[0]  # remove thread part\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf335cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state='''Hey James,\n",
    "\n",
    "I just wanted to touch base with you about a new project I am working on.\n",
    "\n",
    "I've got some research data on this topic that I'd like to share with you. Let's talk about it over coffee/beer/wine/whatever.\n",
    "\n",
    "I've attached the PDF of our whitepaper.\n",
    "\n",
    "Regards,\n",
    "Paul Walker\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c25bb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = preProcessText(prompt)\n",
    "# prompt = f\"Write a response for me to the email.\\nEmail:\\n{state}\\n\\n###\\n\\nResponse:\\n\"\n",
    "# prompt = f\"Answer the following question.\\nQuestion: How do I make chicken masala\\n\\n###\\n\\nAnswer:\\n\"\n",
    "state = preProcessText(state)\n",
    "prompt = f\"Response to the following email.\\nEmail:\\n{state}.\\n\\n###\\nResponse:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b1fb568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to the following email.\n",
      "Email:\n",
      "Hey James, I just wanted to touch base with you about a new project I am working on. I've got some research data on this topic that I'd like to share with you. Let's talk about it over coffee/beer/wine/whatever. I've attached the PDF of our whitepaper. Regards, Paul Walker .\n",
      "\n",
      "###\n",
      "Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40a7b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloom(state):\n",
    "    end_sequence='###'\n",
    "    state = state.replace('\"','')\n",
    "\n",
    "    prompt = f\"Response to the following email.\\nEmail:\\n{state}\\n\\n###\\nResponse:\\n\"\n",
    "    import requests\n",
    "\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom\"\n",
    "    headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "    result_length = 250\n",
    "\n",
    "    def query(payload):\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        return response.json()\n",
    "\n",
    "    output = query({\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\" : {\n",
    "                         \"temperature\": 0.5,\n",
    "                          \"max_new_tokens\":200,\n",
    "            \"eos_token_id\": int(tokenizer.convert_tokens_to_ids(end_sequence)),\n",
    "        \"return_full_text\": False,\n",
    "\n",
    "\n",
    "                        },\n",
    "                \"options\": \n",
    "            {  \n",
    "                \"use_cache\": False,\n",
    "            }\n",
    "        })\n",
    "\n",
    "    new = output[0]['generated_text']\n",
    "\n",
    "    new = new.split(\"###\")[0]\n",
    "    check = new\n",
    "    output = check\n",
    "    \n",
    "    ls_state = state.split('.')\n",
    "    out2 = output.split('.')\n",
    "    for i in ls_state:\n",
    "        if i in out2:\n",
    "            out2.remove(i)\n",
    "            \n",
    "    out2 = list(dict.fromkeys(out2))\n",
    "    output = '.'.join(out2)\n",
    "    \n",
    "    out2 = output.split('\\n')\n",
    "    \n",
    "    for i in ls_state:\n",
    "        if i in out2:\n",
    "            out2.remove(i)\n",
    "            \n",
    "    out2 = list(dict.fromkeys(out2))\n",
    "    output = ' '.join(out2)\n",
    "    \n",
    "    \n",
    "    output = output.replace(state,'')\n",
    "    \n",
    "    out3 = output.split(\"\\n\\n\")\n",
    "    output = out3[0]    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4da6985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3(state):\n",
    "    import requests\n",
    "    text = state\n",
    "    selectedTone = \"Professional\"\n",
    "\n",
    "    API_URL = \"https://punch.punchleadgen.com/api/generate-response\"\n",
    "    payload = {\"email\": f'\"\"\"{text}\"\"\"', \"tone\": selectedTone}\n",
    "    files = []\n",
    "    headers = {}\n",
    "    response = requests.request(\n",
    "        \"POST\", API_URL, headers=headers, data=payload, files=files\n",
    "    )\n",
    "    json_response = response.json()\n",
    "    lead_response = json_response[\"output\"][\"choices\"][0][\"text\"]\n",
    "    final_response = f\"GPT:{lead_response}\"\n",
    "    \n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af5f7228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to the following email.\n",
      "Email:\n",
      "Hey James, I just wanted to touch base with you about a new project I am working on. I've got some research data on this topic that I'd like to share with you. Let's talk about it over coffee/beer/wine/whatever. I've attached the PDF of our whitepaper. Regards, Paul Walker .\n",
      "\n",
      "###\n",
      "Response:\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "GPT:\n",
      "Hi Paul,\n",
      "\n",
      "Thank you for reaching out. I appreciate the opportunity to discuss your project with you. Let's schedule a meeting to discuss your data further. Thank you for providing the PDF of the white paper. I look forward to hearing more about your project.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "BLOOM:\n",
      "Hi Paul, Thanks for the email. I would love to have a chat with you about this project. I am in town this week, so if you are free on Tuesday afternoon, let me know and we can meet up. Regards, James \n"
     ]
    }
   ],
   "source": [
    "final_response = gpt3(state)\n",
    "output = bloom(state)\n",
    "\n",
    "print(prompt+\"\\n\\n\"+\"-\"*100+\"\\n\"+final_response+\"\\n\"+\"-\"*100+\"\\n\" +\"\\n\"+\"BLOOM:\\n\" +output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b368ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
